{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65f2a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures, MaxAbsScaler, FunctionTransformer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, concatenate, Flatten, Dropout \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.base import TransformerMixin, BaseEstimator, RegressorMixin\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b4f6f5",
   "metadata": {},
   "source": [
    "### Extract Image Features using pretrained CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ef89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)\n",
    "\n",
    "# base model for transfer learning\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "\n",
    "%%time\n",
    "image_size = (224, 224)\n",
    "zoom_level=[16.25, 11.5]\n",
    "parent_folder=r'.\\Capstone\\Satellite Images'\n",
    "satellite_images=[]\n",
    "\n",
    "subfolder0=os.path.join(parent_folder, f'zoom-{zoom_level[0]}')\n",
    "subfolder1=os.path.join(parent_folder, f'zoom-{zoom_level[1]}')\n",
    "counter=0\n",
    "batch_size=5000\n",
    "\n",
    "images_array0 = np.empty((0, image_size[0], image_size[1], 3), dtype=np.float32)\n",
    "images_array1 = np.empty((0, image_size[0], image_size[1], 3), dtype=np.float32)\n",
    "\n",
    "image_features = np.empty((0,50176), dtype=np.float32)\n",
    "\n",
    "\n",
    "for Id in X_final['id'][:10]:  \n",
    "    \n",
    "    file_name0 = Id+f'-{zoom_level[0]}.jpg'\n",
    "    file_name1 = Id+f'-{zoom_level[1]}.jpg'\n",
    "    img_path0 = os.path.join(subfolder0, file_name0)\n",
    "    img_path1 = os.path.join(subfolder1, file_name1)\n",
    "    \n",
    "    img0=load_img(img_path0, target_size=image_size) #load and process image at zoom_level[0]\n",
    "    img0 = img_to_array(img0)\n",
    "    img0 = preprocess_input(img0)\n",
    "    img0= np.expand_dims(img0, axis=0) #add extra dimension for appending\n",
    "    images_array0=np.append(images_array0, img0, axis=0)\n",
    "    \n",
    "    img1=load_img(img_path1, target_size=image_size) #load and process image at zoom_level[1]\n",
    "    img1 = img_to_array(img1)\n",
    "    img1 = preprocess_input(img1)\n",
    "    img1=np.expand_dims(img1, axis=0) #add extra dimension for appending\n",
    "    images_array1=np.append(images_array1, img1, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    if counter%batch_size==0:\n",
    "        \n",
    "        img_features0 = base_model.predict(images_array0, verbose=0)\n",
    "        img_features0 = img_features0.reshape(img_features0.shape[0], -1) #flatten feature matrices \n",
    "                \n",
    "        img_features1 = base_model.predict(images_array1, verbose=0)\n",
    "        img_features1 = img_features1.reshape(img_features1.shape[0], -1) #flatten feature matrices \n",
    "        \n",
    "        feature_stack = np.hstack((img_features0, img_features1))\n",
    "        image_features= np.append(image_features, feature_stack, axis=0)\n",
    "        \n",
    "        #clear image arrays for next batch        \n",
    "        images_array0 = np.empty((0, image_size[0], image_size[1], 3), dtype=np.float32)\n",
    "        images_array1 = np.empty((0, image_size[0], image_size[1], 3), dtype=np.float32)\n",
    "   \n",
    "       \n",
    "    counter+=1\n",
    "    if counter%5000==0:\n",
    "        print(counter,'images processed')\n",
    "        \n",
    "#process remaining images if any\n",
    "img_features0 = base_model.predict(images_array0, verbose=0)\n",
    "img_features0 = img_features0.reshape(img_features0.shape[0], -1) #flatten feature matrices \n",
    "img_features1 = base_model.predict(images_array1, verbose=0)\n",
    "img_features1 = img_features1.reshape(img_features1.shape[0], -1) #flatten feature matrices \n",
    "\n",
    "feature_stack = np.hstack((img_features0, img_features1))\n",
    "image_features= np.append(image_features, feature_stack, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#reducing demionality of image features data using PCA to make it easier to process\n",
    "\n",
    "%%time\n",
    "pca = PCA(n_components=2500)  \n",
    "reduced_features_2500 = pca.fit_transform(image_features)\n",
    "\n",
    "# Explained variance ratio\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "#print(f\"Explained Variance Ratio of PC1 and PC2: {explained_variance}\")\n",
    "\n",
    "sum(explained_variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e115ba",
   "metadata": {},
   "source": [
    "### Pipeline to process Home Features and Demographics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e54ec824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_julian(date_df):\n",
    "    series = date_df.squeeze()\n",
    "    return np.array(series.apply(lambda x: x.to_julian_date())).reshape(-1, 1)\n",
    "\n",
    "class DistanceTransfomer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, places):\n",
    "        self.places = places\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        result = []\n",
    "        for place in self.places:\n",
    "            result.append(np.sqrt(((X.values - place)**2).sum(axis=1)).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782ba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#locations\n",
    "PHL = (39.87368234690642, -75.24350488095705)\n",
    "City_Hall = (39.95281182498322, -75.1615591562166)\n",
    "KOP_mall = (40.08864933327422, -75.390381745456)\n",
    "\n",
    "locations = [PHL, City_Hall, KOP_mall]\n",
    "\n",
    "\n",
    "categorical_columns=['zipCode']\n",
    "numeric_columns = ['bathrooms', 'bedrooms', 'squareFootage', 'Median household income', 'Median Value of Owner-occupied units ']\n",
    "\n",
    "\n",
    "pipe_yearBuilt= Pipeline([('impute', SimpleImputer(strategy='most_frequent'))#,\n",
    "                          #('poly', PolynomialFeatures(degree=1))\n",
    "                         ])\n",
    "\n",
    "\n",
    "pipe_lastSaleDate = Pipeline([('to_julian', FunctionTransformer(apply_julian)),\n",
    "                              ('impute', SimpleImputer(strategy='median'))#,\n",
    "                              #('poly', PolynomialFeatures(degree=2))\n",
    "                             ])\n",
    "\n",
    "pipe_demo_poly = Pipeline([('impute', SimpleImputer(strategy='median'))#,\n",
    "                           #('poly', PolynomialFeatures(degree=2))\n",
    "                          ])\n",
    "\n",
    "\n",
    "\n",
    "ct = ColumnTransformer([('cat', OneHotEncoder(), categorical_columns),\n",
    "                        ('numeric_impute', SimpleImputer(strategy='median'), numeric_columns),\n",
    "                        ('distances', DistanceTransfomer(locations), ['latitude', 'longitude']),\n",
    "                        ('pipe_yearBuilt', pipe_yearBuilt, ['yearBuilt']),\n",
    "                        ('pipe_lastSaleDate',  pipe_lastSaleDate, ['lastSaleDate']),\n",
    "                        ('pipe_demo_poly',  pipe_demo_poly, ['Employed Population %', 'Minority Pop % Calc', 'Median age (years)']),\n",
    "                       ])\n",
    "\n",
    "ct_home_features_only = ColumnTransformer([('cat', OneHotEncoder(), categorical_columns),\n",
    "                        ('numeric_impute', SimpleImputer(strategy='median'), numeric_columns[0:3]),\n",
    "                        ('distances', DistanceTransfomer(locations), ['latitude', 'longitude']),\n",
    "                        ('pipe_yearBuilt', pipe_yearBuilt, ['yearBuilt']),\n",
    "                        ('pipe_lastSaleDate',  pipe_lastSaleDate, ['lastSaleDate'])\n",
    "                       ])\n",
    "\n",
    "\n",
    "\n",
    "lin_pipe = Pipeline([('ct_transformer', ct),\n",
    "                 #('poly', PolynomialFeatures(degree=2)),\n",
    "                 ('scaler', MaxAbsScaler())\n",
    "                 #('ridge', Ridge(alpha=0))\n",
    "                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc58cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X and y datasets\n",
    "\n",
    "with open(r'X_final.pkd', 'rb') as f:\n",
    "     X_final = dill.load(f)\n",
    "\n",
    "X=X_final.drop('lastSalePrice', axis=1)\n",
    "y=X_final['lastSalePrice']\n",
    "\n",
    "#home_features_sparse=lin_pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6081852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining reduced image features datasets with the output of lin_pipe\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "demo_home_data= lin_pipe.fit_transform(X)\n",
    "\n",
    "combined_data_3000 = hstack((demo_home_data, reduced_features_3000))\n",
    "combined_data_2000 = hstack((demo_home_data, reduced_features_2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = Pipeline([('scaler', MaxAbsScaler()),\n",
    "                       ('ridge', Ridge(alpha=0))])\n",
    "\n",
    "\n",
    "grid_searcher_2000= GridSearchCV(lin_model, \n",
    "                                 {'ridge__alpha': [0, 1, 10]},\n",
    "                                 n_jobs=2, \n",
    "                                 cv=5)\n",
    "\n",
    "grid_searcher_3000= GridSearchCV(lin_model, \n",
    "                                 {'ridge__alpha': [0, 1, 10]},\n",
    "                                 n_jobs=2, \n",
    "                                 cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search with pca n_components = 2000 \n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "combined_data_2000_shuffled, y_shuffled = shuffle(combined_data_2000, y, random_state=42)\n",
    "grid_searcher_2000.fit(combined_data_2000_shuffled, y_shuffled)\n",
    "\n",
    "print(grid_searcher_2000.best_params_)\n",
    "print(grid_searcher_2000.score(combined_data_2000_shuffled, y_shuffled))\n",
    "grid_searcher_2000.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search with pca n_components = 3000 \n",
    "\n",
    "combined_data_3000_shuffled, y_shuffled = shuffle(combined_data_3000, y, random_state=42)\n",
    "grid_searcher_3000.fit(combined_data_3000_shuffled, y_shuffled)\n",
    "print(grid_searcher_3000.best_params_)\n",
    "print(grid_searcher_3000.score(combined_data_3000_shuffled, y_shuffled))\n",
    "grid_searcher_3000.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search with pca n_components = 3000 \n",
    "\n",
    "#copied output for grid_searcher_3000\n",
    "\"\"\"\n",
    "{'ridge__alpha': 0}\n",
    "0.7473774897676411\n",
    "{'mean_fit_time': array([248.07357888,  83.96293612,  58.84812312]),\n",
    " 'std_fit_time': array([15.07273627,  2.63493217,  4.17996321]),\n",
    " 'mean_score_time': array([2.26447978, 1.91136951, 1.96938534]),\n",
    " 'std_score_time': array([0.42178446, 0.82405852, 0.98727506]),\n",
    " 'param_ridge__alpha': masked_array(data=[0, 1, 10],\n",
    "              mask=[False, False, False],\n",
    "        fill_value='?',\n",
    "             dtype=object),\n",
    " 'params': [{'ridge__alpha': 0}, {'ridge__alpha': 1}, {'ridge__alpha': 10}],\n",
    " 'split0_test_score': array([0.71564913, 0.69625264, 0.67562538]),\n",
    " 'split1_test_score': array([0.71166675, 0.6904854 , 0.66818436]),\n",
    " 'split2_test_score': array([0.71999322, 0.70245437, 0.6839968 ]),\n",
    " 'split3_test_score': array([0.70954531, 0.70098276, 0.68574379]),\n",
    " 'split4_test_score': array([0.69915166, 0.696173  , 0.6977118 ]),\n",
    " 'mean_test_score': array([0.71120121, 0.69726963, 0.68225243]),\n",
    " 'std_test_score': array([0.00700334, 0.00421738, 0.00996045]),\n",
    " 'rank_test_score': array([1, 2, 3])}\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non linear model\n",
    "\n",
    "non_lin_model = Pipeline([#('ct_transformer', ct),\n",
    "                 #('poly', PolynomialFeatures(degree=2)),\n",
    "                 ('scaler', MaxAbsScaler()),\n",
    "                 ('rf', RandomForestRegressor(n_estimators=100, max_depth=20, min_samples_leaf=25))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03dee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full model fits a linear model and then fits a non linear model on the residuals of the linear model\n",
    "\n",
    "\n",
    "class FullModel (BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__ (self, lin_model, non_lin_model):\n",
    "        self.lin_model = lin_model\n",
    "        self.non_lin_model = non_lin_model\n",
    "        \n",
    "    def fit (self, X, y):\n",
    "        \n",
    "        \"\"\"fit linaer model\"\"\"\n",
    "        self.lin_model.fit(X, y)\n",
    "        residuals = y - self.lin_model.predict(X)\n",
    "        \n",
    "        \"\"\"fit non linear model\"\"\"\n",
    "        self.non_lin_model.fit(X, residuals)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        lin_pred = self.lin_model.predict(X)\n",
    "        non_lin_pred = self.non_lin_model.predict(X)\n",
    "        final_pred = lin_pred + non_lin_pred\n",
    "        return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c4797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_estimator = FullModel(lin_model, non_lin_model)\n",
    "price_estimator.fit(combined_data_2000, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "794462c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_model.pkd', 'rb') as f:\n",
    "    price_estimator = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1815264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('combined_data_2000.pkd', 'rb') as f:\n",
    "    combined_data_2000 = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faaedf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_abs_error: 55850.06112617552, R Squared: 0.8354817609602162\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "# Final Model Results\n",
    "\n",
    "print(f'mean_abs_error: {mean_absolute_error(y, price_estimator.predict(combined_data_2000))}\\\n",
    ", R Squared: {r2_score(y, price_estimator.predict(combined_data_2000))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef4674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64d89fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
